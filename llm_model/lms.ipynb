{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahil/Question_Answ/question/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "##impor every thing that are need in this project \n",
    "import os \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback \n",
    "import PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in this project i use gemini \n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## that are the format of response \n",
    "\n",
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this template 1 \n",
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone.\n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\" \n",
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis.\n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahil/Question_Answ/question/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:151: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "## create the prompt \n",
    "\n",
    "quiz_generation_prompt=PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    ") \n",
    "\n",
    "## now create a chain for prompt one \n",
    "\n",
    "llm_chain1=LLMChain(llm=llm,prompt=quiz_generation_prompt,output_key=\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create prompt for second template \n",
    "\n",
    "quiz_evaluation_prompt=PromptTemplate(\n",
    "    input_variables=[\"subject\",\"quiz\"],\n",
    "    template=TEMPLATE2\n",
    ") \n",
    "\n",
    "review_chain=LLMChain(llm=llm,prompt=quiz_evaluation_prompt,output_key=\"review\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now use squentail chain \n",
    "\n",
    "generate_evaluate_chain=SequentialChain(chains=[llm_chain1, review_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "                                        output_variables=[\"quiz\", \"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "## now test our model \n",
    "# file_path=\"/home/sahil/Question_Answ/data.txt\"\n",
    "# with open(file_path, 'r') as file:\n",
    "#     TEXT = file.read() \n",
    "def read_file(file_path):\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            pdf_reader = PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/sahil/Question_Answ/yolo.pdf\" \n",
    "text=read_file(path) \n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER=10\n",
    "SUBJECT=\"CNN\"\n",
    "TONE=\"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahil/Question_Answ/question/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:151: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "response=generate_evaluate_chain(\n",
    "        {\n",
    "            \"text\": text,\n",
    "            \"number\": NUMBER,\n",
    "            \"subject\":SUBJECT,\n",
    "            \"tone\": TONE,\n",
    "            \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "        }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=response.get(\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"What is the main idea behind the YOLO object detection system?\", \"options\": {\"a\": \"Using a single convolutional network to predict bounding boxes and class probabilities directly from images.\", \"b\": \"Repurposing classifiers to perform object detection.\", \"c\": \"Using region proposal methods to generate potential bounding boxes.\", \"d\": \"Employing a sliding window approach to evaluate classifiers at various locations.\"}, \"correct\": \"a\"}, \"2\": {\"mcq\": \"How does YOLO reason globally about the image?\", \"options\": {\"a\": \"By dividing the image into a grid and having each grid cell predict bounding boxes and class probabilities.\", \"b\": \"By using a sliding window approach to evaluate the entire image.\", \"c\": \"By generating region proposals and running a classifier on each proposed box.\", \"d\": \"By using a complex pipeline of separate components.\"}, \"correct\": \"a\"}, \"3\": {\"mcq\": \"What are the benefits of YOLO\\'s unified architecture?\", \"options\": {\"a\": \"It is extremely fast and can process images in real-time.\", \"b\": \"It learns generalizable representations of objects.\", \"c\": \"It makes fewer localization errors than other methods.\", \"d\": \"All of the above.\"}, \"correct\": \"d\"}, \"4\": {\"mcq\": \"What is the main difference between YOLO and traditional object detection methods?\", \"options\": {\"a\": \"YOLO uses a single neural network while traditional methods use separate components.\", \"b\": \"YOLO is faster and more accurate than traditional methods.\", \"c\": \"YOLO learns generalizable representations of objects while traditional methods do not.\", \"d\": \"YOLO is easier to train and optimize than traditional methods.\"}, \"correct\": \"a\"}, \"5\": {\"mcq\": \"How does YOLO handle the prediction of multiple bounding boxes per grid cell?\", \"options\": {\"a\": \"It uses non-maximal suppression to eliminate duplicate detections.\", \"b\": \"It assigns one bounding box predictor to be responsible for each object.\", \"c\": \"It predicts all bounding boxes across all classes simultaneously.\", \"d\": \"It uses a separate classifier for each bounding box.\"}, \"correct\": \"b\"}, \"6\": {\"mcq\": \"What is the main source of error in YOLO?\", \"options\": {\"a\": \"Incorrect classification of objects.\", \"b\": \"Incorrect localization of objects.\", \"c\": \"False positives on background.\", \"d\": \"Missing objects in the image.\"}, \"correct\": \"b\"}, \"7\": {\"mcq\": \"How does YOLO compare to Fast R-CNN in terms of localization and background errors?\", \"options\": {\"a\": \"YOLO makes more localization errors but fewer background errors than Fast R-CNN.\", \"b\": \"YOLO makes fewer localization errors but more background errors than Fast R-CNN.\", \"c\": \"YOLO and Fast R-CNN have similar error rates.\", \"d\": \"YOLO is more accurate than Fast R-CNN in all aspects.\"}, \"correct\": \"a\"}, \"8\": {\"mcq\": \"How does combining YOLO with Fast R-CNN improve performance?\", \"options\": {\"a\": \"YOLO\\'s ability to eliminate background detections from Fast R-CNN results in a significant performance boost.\", \"b\": \"YOLO\\'s faster processing speed allows for a more efficient combination with Fast R-CNN.\", \"c\": \"YOLO\\'s generalizable representations of objects complement Fast R-CNN\\'s accuracy.\", \"d\": \"YOLO and Fast R-CNN have complementary strengths that result in a more robust system.\"}, \"correct\": \"a\"}, \"9\": {\"mcq\": \"Why does YOLO generalize better to new domains than other detection systems?\", \"options\": {\"a\": \"It uses a single convolutional network that learns generalizable representations of objects.\", \"b\": \"It is trained on a loss function that directly corresponds to detection performance.\", \"c\": \"It models the size and shape of objects, as well as relationships between objects.\", \"d\": \"All of the above.\"}, \"correct\": \"d\"}, \"10\": {\"mcq\": \"What makes YOLO suitable for real-time applications?\", \"options\": {\"a\": \"Its ability to process images in real-time with low latency.\", \"b\": \"Its high accuracy and generalizability.\", \"c\": \"Its ability to handle a variety of objects simultaneously.\", \"d\": \"All of the above.\"}, \"correct\": \"d\"}\\n}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz=quiz.split(\"### RESPONSE_JSON\\n\")[1]\n",
    "quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=json.loads(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MCQ': 'What is the main idea behind the YOLO object detection system?',\n",
       "  'Choices': 'a: Using a single convolutional network to predict bounding boxes and class probabilities directly from images. | b: Repurposing classifiers to perform object detection. | c: Using region proposal methods to generate potential bounding boxes. | d: Employing a sliding window approach to evaluate classifiers at various locations.',\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': 'How does YOLO reason globally about the image?',\n",
       "  'Choices': 'a: By dividing the image into a grid and having each grid cell predict bounding boxes and class probabilities. | b: By using a sliding window approach to evaluate the entire image. | c: By generating region proposals and running a classifier on each proposed box. | d: By using a complex pipeline of separate components.',\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': \"What are the benefits of YOLO's unified architecture?\",\n",
       "  'Choices': 'a: It is extremely fast and can process images in real-time. | b: It learns generalizable representations of objects. | c: It makes fewer localization errors than other methods. | d: All of the above.',\n",
       "  'Correct': 'd'},\n",
       " {'MCQ': 'What is the main difference between YOLO and traditional object detection methods?',\n",
       "  'Choices': 'a: YOLO uses a single neural network while traditional methods use separate components. | b: YOLO is faster and more accurate than traditional methods. | c: YOLO learns generalizable representations of objects while traditional methods do not. | d: YOLO is easier to train and optimize than traditional methods.',\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': 'How does YOLO handle the prediction of multiple bounding boxes per grid cell?',\n",
       "  'Choices': 'a: It uses non-maximal suppression to eliminate duplicate detections. | b: It assigns one bounding box predictor to be responsible for each object. | c: It predicts all bounding boxes across all classes simultaneously. | d: It uses a separate classifier for each bounding box.',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'What is the main source of error in YOLO?',\n",
       "  'Choices': 'a: Incorrect classification of objects. | b: Incorrect localization of objects. | c: False positives on background. | d: Missing objects in the image.',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'How does YOLO compare to Fast R-CNN in terms of localization and background errors?',\n",
       "  'Choices': 'a: YOLO makes more localization errors but fewer background errors than Fast R-CNN. | b: YOLO makes fewer localization errors but more background errors than Fast R-CNN. | c: YOLO and Fast R-CNN have similar error rates. | d: YOLO is more accurate than Fast R-CNN in all aspects.',\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': 'How does combining YOLO with Fast R-CNN improve performance?',\n",
       "  'Choices': \"a: YOLO's ability to eliminate background detections from Fast R-CNN results in a significant performance boost. | b: YOLO's faster processing speed allows for a more efficient combination with Fast R-CNN. | c: YOLO's generalizable representations of objects complement Fast R-CNN's accuracy. | d: YOLO and Fast R-CNN have complementary strengths that result in a more robust system.\",\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': 'Why does YOLO generalize better to new domains than other detection systems?',\n",
       "  'Choices': 'a: It uses a single convolutional network that learns generalizable representations of objects. | b: It is trained on a loss function that directly corresponds to detection performance. | c: It models the size and shape of objects, as well as relationships between objects. | d: All of the above.',\n",
       "  'Correct': 'd'},\n",
       " {'MCQ': 'What makes YOLO suitable for real-time applications?',\n",
       "  'Choices': 'a: Its ability to process images in real-time with low latency. | b: Its high accuracy and generalizability. | c: Its ability to handle a variety of objects simultaneously. | d: All of the above.',\n",
       "  'Correct': 'd'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz.to_csv(\"ml5.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "question",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
